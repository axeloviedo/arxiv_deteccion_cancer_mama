<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Detalles Técnicos - Entrenamiento del Modelo</title>
    <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="bg-gradient-to-r from-gray-800 via-gray-700 to-gray-900 text-white">
    <div class="min-h-screen flex flex-col items-center justify-center py-12 px-4">
        <h1 class="text-4xl font-bold mb-6 text-center">Detalles Técnicos del Modelo</h1>

        <div class="max-w-4xl text-lg space-y-6 text-justify">
            <p>
                El modelo fue entrenado utilizando una arquitectura llamada <b>ResNet50</b>, una red neuronal convolucional (CNN) ampliamente utilizada en tareas de visión por computadora. Esta arquitectura incluye capas avanzadas que ayudan a identificar patrones complejos en imágenes, como texturas y formas características del carcinoma ductal invasivo (IDC).
            </p>

            <h2 class="text-2xl font-semibold text-center mt-6">1. Preprocesamiento de las Imágenes</h2>
            <ul class="list-disc list-inside space-y-2">
                <li>Las imágenes se normalizaron a valores entre 0 y 1.</li>
                <li>Se aplicaron técnicas de data augmentation como rotación, cambio de escala, desplazamiento y volteo horizontal para mejorar la generalización del modelo.</li>
            </ul>

            <h2 class="text-2xl font-semibold text-center mt-6">2. Entrenamiento del Modelo</h2>
            <p>
                El modelo base de ResNet50 fue cargado con pesos preentrenados en el conjunto de datos ImageNet. Posteriormente, se añadieron capas adicionales para adaptar la red a la tarea de clasificación binaria (IDC positivo y negativo). Las capas añadidas incluyen:
            </p>
            <ul class="list-disc list-inside space-y-2">
                <li><b>GlobalAveragePooling2D:</b> Para reducir la dimensionalidad de las características aprendidas.</li>
                <li><b>Capa densa (128 unidades, ReLU):</b> Para capturar patrones específicos del dataset.</li>
                <li><b>Capa de salida (1 unidad, Sigmoid):</b> Para producir una probabilidad de clasificación binaria.</li>
            </ul>
            <p>El modelo utilizó la función de activación <b>sigmoid</b> en la capa de salida y la función de pérdida <b>binary_crossentropy</b>.</p>

            <h2 class="text-2xl font-semibold text-center mt-6">3. Resultados del Entrenamiento</h2>
            <p>El entrenamiento se realizó durante <b>130 pasos</b> utilizando un optimizador <b>Adam</b> con una tasa de aprendizaje ajustada. Aquí están los resultados clave:</p>
            <ul class="list-disc list-inside space-y-2">
                <li><b>Precisión final en entrenamiento:</b> 89.07%.</li>
                <li><b>Pérdida:</b> 0.2456.</li>
                <li><b>Tiempo total de entrenamiento:</b> Aprox. 100 segundos por paso.</li>
            </ul>

            <h2 class="text-2xl font-semibold text-center mt-6">4. Evaluación del Modelo</h2>
            <p>
                Para evaluar el modelo, se utilizó un conjunto de prueba independiente compuesto por 4134 imágenes. Los resultados clave incluyen:
            </p>
            <ul class="list-disc list-inside space-y-2">
                <li><b>Precisión en prueba:</b> 87%.</li>
                <li><b>Matriz de confusión:</b></li>
            </ul>
            <div class="bg-white text-black p-4 rounded-lg">
                <pre>
[[2688  266]
 [ 291  889]]
                </pre>
            </div>
            <p>Reporte de clasificación:</p>
            <div class="bg-white text-black p-4 rounded-lg">
                <pre>
              precision    recall  f1-score   support

           0       0.90      0.91      0.91      2954
           1       0.77      0.75      0.76      1180

    accuracy                           0.87      4134
   macro avg       0.84      0.83      0.83      4134
weighted avg       0.86      0.87      0.86      4134
                </pre>
            </div>

            <h2 class="text-2xl font-semibold text-center mt-6">5. Conclusión Técnica</h2>
            <p>
                Este modelo es una herramienta prometedora para identificar patrones de cáncer en imágenes de tejido mamario. Los resultados muestran una precisión del 87%, pero la clase IDC positivo requiere mejoras, como el balanceo de clases o el uso de técnicas más avanzadas en iteraciones futuras.
            </p>
        </div>

        <a href="/" class="mt-8 bg-blue-500 text-white py-2 px-4 rounded-lg hover:bg-blue-600 transition duration-300">Volver al Inicio</a>
    </div>
</body>
</html>
